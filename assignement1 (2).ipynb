{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load the CSV file into three classes of positive, neutral and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "class Positive:\n",
    "    def __init__(self, text, sentiment):\n",
    "        self.text = text\n",
    "        self.sentiment = sentiment      \n",
    "        \n",
    "class Neutral:\n",
    "    def __init__(self, text, sentiment):\n",
    "        self.text = text\n",
    "        self.sentiment = sentiment\n",
    "        \n",
    "class Negative:\n",
    "    def __init__(self, text, sentiment):\n",
    "        self.text = text\n",
    "        self.sentiment = sentiment\n",
    "    \n",
    "\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "\n",
    "\n",
    "with open(\"Tweets.csv\", encoding=\"utf-8\") as r:\n",
    "    reader = csv.DictReader(r)\n",
    "    for linje in reader:\n",
    "        if linje[\"airline_sentiment\"] == \"positive\":\n",
    "            positive.append(Positive(linje[\"text\"], linje[\"airline_sentiment\"]))\n",
    "        elif linje[\"airline_sentiment\"] == \"neutral\":\n",
    "            neutral.append(Neutral(linje[\"text\"], linje[\"airline_sentiment\"]))\n",
    "        else:\n",
    "            negative.append(Negative(linje[\"text\"], linje[\"airline_sentiment\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "Split up data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(positive)\n",
    "random.shuffle(neutral)\n",
    "random.shuffle(negative)\n",
    "\n",
    "train_pos = positive[:2000]\n",
    "train_neu = neutral[:2000]\n",
    "train_neg = negative[:2000]\n",
    "\n",
    "test_pos = positive[2000:]\n",
    "test_neu = neutral[2000:]\n",
    "test_neg = negative[2000:]\n",
    "\n",
    "test_tweets = test_pos + test_neu + test_neg\n",
    "random.shuffle(test_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words \n",
    "Vectorize words and create words probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "pos_vectorizer = CountVectorizer(max_df = 0.95, stop_words = stopwords.words('english'))\n",
    "neu_vectorizer = CountVectorizer(max_df = 0.95, stop_words = stopwords.words('english'))\n",
    "neg_vectorizer = CountVectorizer(max_df = 0.95, stop_words = stopwords.words('english'))\n",
    "\n",
    "    \n",
    "train_pos_vectors = pos_vectorizer.fit_transform(x.text for x in train_pos)\n",
    "train_neu_vectors = neu_vectorizer.fit_transform(x.text for x in train_neu)\n",
    "train_neg_vectors = neg_vectorizer.fit_transform(x.text for x in train_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lager to funksjoner. En til å beregne sannsynlighet og den andre til å multiplisere alle tall i en liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_probability(dataframe):\n",
    "    temp_dict = {}\n",
    "    for column in dataframe:\n",
    "        temp_dict[column] = (dataframe[column].sum() / dataframe.values.sum())\n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "def multiply_list(liste):\n",
    "    i = 1\n",
    "    for element in liste:\n",
    "        i *= element\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    pos_dict = {}\n",
    "    neu_dict = {}\n",
    "    neg_dict = {}\n",
    "    \n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_pos_vectors, train_neu_vectors, train_neg_vectors):\n",
    "        \n",
    "        pos = pd.DataFrame(train_pos_vectors.toarray(), columns=pos_vectorizer.get_feature_names())\n",
    "        neu = pd.DataFrame(train_neu_vectors.toarray(), columns=neu_vectorizer.get_feature_names())\n",
    "        neg = pd.DataFrame(train_neg_vectors.toarray(), columns=neg_vectorizer.get_feature_names())\n",
    "        \n",
    "        self.pos_dict = sentiment_probability(pos)\n",
    "        self.neu_dict = sentiment_probability(neu)\n",
    "        self.neg_dict = sentiment_probability(neg)\n",
    "        \n",
    "    def predict(self, sentence, generator = True):\n",
    "        temp_pos = []\n",
    "        temp_neu = []\n",
    "        temp_neg = []\n",
    "        \n",
    "        total_words = 1 / (len(self.pos_dict) + len(self.neu_dict) + len(self.neg_dict))\n",
    "        sentence = word_tokenize(sentence.lower())\n",
    "        \n",
    "        for word in sentence:\n",
    "            if word in list(self.pos_dict.keys()):\n",
    "                temp_pos.append(self.pos_dict[word] + total_words)\n",
    "            else:\n",
    "                temp_pos.append(total_words)\n",
    "                \n",
    "        for word in sentence:\n",
    "            if word in list(self.neu_dict.keys()):\n",
    "                temp_neu.append(self.neu_dict[word] + total_words)\n",
    "            else:\n",
    "                temp_neu.append(total_words)\n",
    "                \n",
    "        for word in sentence:\n",
    "            if word in list(self.neg_dict.keys()):\n",
    "                temp_neg.append(self.neg_dict[word] + total_words)\n",
    "            else:\n",
    "                temp_neg.append(total_words) \n",
    "        \n",
    "        if (multiply_list(temp_neg) > multiply_list(temp_pos)) and (multiply_list(temp_neg) > multiply_list(temp_neu)):\n",
    "            prediction = \"negative\"\n",
    "            key_word = sentence[temp_neg.index(max(temp_neg))]\n",
    "            \n",
    "        elif (multiply_list(temp_neu) > multiply_list(temp_pos)) and (multiply_list(temp_neu) > multiply_list(temp_neg)):\n",
    "            prediction = \"neutral\"\n",
    "            key_word = sentence[temp_neu.index(max(temp_neu))]\n",
    "            \n",
    "        elif (multiply_list(temp_pos) > multiply_list(temp_neu)) and (multiply_list(temp_pos) > multiply_list(temp_neg)):\n",
    "            prediction = \"positive\"\n",
    "            key_word = sentence[temp_pos.index(max(temp_pos))]\n",
    "            \n",
    "        if generator == True: \n",
    "            print(\"Because of the word: \" + str(key_word) + \"\\nOur classifier predicts:\", prediction)\n",
    "            return prediction\n",
    "        else:\n",
    "            return prediction\n",
    "        \n",
    "    def evaluate(self, test_tweets):\n",
    "        test_score = []\n",
    "        pos_score = []\n",
    "        neu_score = []\n",
    "        neg_score = []\n",
    "        \n",
    "        for objekt in test_tweets:\n",
    "            if self.predict(objekt.text, False) == objekt.sentiment: #Setter generator til False, så vi ikke får ut tekst\n",
    "                test_score.append(1)\n",
    "            else:\n",
    "                test_score.append(0)\n",
    "                \n",
    "        return (sum(test_score)/len(test_score))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaiveBayes() #Initaliserer modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(train_pos_vectors, train_neu_vectors, train_neg_vectors) #kjører treningsdataen gjennom naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545138888888889"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.evaluate(test_tweets) #tester modellen opp mot testdataen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.predicts() #Skriv inn tekst å teste "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
